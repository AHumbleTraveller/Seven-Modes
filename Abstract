Abstract:
What is intelligence? In Simon and Binets’ 1916 paper, ‘Intelligence and its measurements,’ they elucidate us by providing the following: ‘That intelligence is one’s ability to adapt to one’s environment.’ But what does this mean, and what are the mechanisms that allow for such adaptability? 

This question has long been the foundation which underlies many a field, be it machine intelligence and its ability to interpret novel information, or biological systems and the means by which they adapt to a changing and uncaring environment. 
In recent years, we’ve seen an increase in effort to create an artificial mind that might approximate that adaptability as expressed by its biological counterpart - the so called neural networks. However, despite advancements made in this noble pursuit, many have been hard pressed to describe the results as truly intelligent. I will not weigh in on such discussions. Instead, this paper will be an attempt to explore a different kind of intelligence, a compound intelligence, whereby the resulting machine has the potential to be both independent and self-actualizing. 

We will be exploring the self-organizing machine that is the Homo sapien, or more specifically, the mind of such an organism. In this, we will deconstruct the top-most structures which form the basis of human cognition, exploring how they work in tandem, giving rise to intelligent behavior. From this we can imagine a synthetic equivalent, equal to that of its carbon-based sibling. 

Our language will try well to remain as agnostic as possible of the underlying substrate, and I will do my best to operate at the level of ‘systems neuroscience,’ or higher. However, a basic understanding of neuroanatomy will serve the reader greatly, as will an understanding of machine learning fundamentals, and information theory. With that said, this work will be divided into three parts: 


Part I will focus on each of the subsystems which comprise the self-organizing machine, of which there are seven: [1] A Compute Surface, [2] an Archival Schema, [3] an Attentional Guidance System, [4] a Federated Locus of Control, [5] a Goal-directed Subroutine, [6] a Memory-tuning subroutine, and finally, [7] the ability to scale such Compute across Agents.

Part II will continue the discussion on the scalability of self-organizing machines, with particular emphasis on the noisy communication channels exhibited between them. 

Part III will bring with it concluding remarks as well as additional exploratory thoughts. We will cover such topics as: The reproductive strategies of cognitive agents, Morality: its biological roots in subcortical spaces, and On the construction of Eidolon’s. In addition to this, Part III will be an exploration of some of the more exotic forms of distributed intelligence. 


Clearly, this third and final section will be far more speculative in nature than Parts I and II (which themselves contain a great deal of inference). As such, it will be impossible for me to discuss such topics without coloring them greatly with personal opinion and belief. The reader would do well to keep this in mind as they explore the volume of this text, but perhaps doubly so upon reaching this third section. 

Finally, the overall purpose of this paper's existence is a complicated one, even to its author. I am a strong advocate of using writing as a means to teach, and teaching as a means to learn. In this way, this paper is not meant for you. It is meant for me. However, should you read the contents gathered herein, and should you feel as I feel, then so too might this paper also be for us; for those whose minds seek neither peace nor contentment, and for those whose souls long for new horizons.
